---
title: "Keynotes and Panel"
---

<!DOCTYPE html>
<!--[if IE 8]>
<html lang="en" class="ie8"> <![endif]-->
<!--[if IE 9]>
<html lang="en" class="ie9"> <![endif]-->
<!--[if !IE]><!-->
<html lang="en">
<!--<![endif]-->

<head>
    <title>SIGIR 2020</title>
    {% include head.html %}
    <!-- <link rel="stylesheet" href="{{ site.baseurl }}/assets/css/header-v3.css"> -->
    <style>
        .abstract p {
            line-height: 1.61em !important;
            margin-bottom: 10px;
            /* font-size:medium; */
        }
    </style>
</head>

<body class="header-fixed">
    <div class="wrapper" style="min-height: 800px">
        <!--=== Header===-->
        <div class="header-v3">
            <div class="container"></div>
            <!-- Navbar -->
            {% include navbar.html %}
            <!-- End Navbar -->
        </div>
        <!--=== End Header ===-->
        <div class="breadcrumbs">
            <div class="container">
                <h1 class="pull-left">Keynotes and Panel</h1>
                <ul class="pull-right breadcrumb">
                    <li><a href="{{ site.baseurl }}/">Home</a></li>
                    <li><a href="">Program</a></li>
                    <li class="active">Keynotes and Panel</li>
                </ul>
            </div>
        </div>

        <div class="bg-color-light">
            <div class="container content-xs">
                <div class="news-v3 abstract margin-bottom-30">
                    {% include banner.html %}
                    <!-- Contents goes here -->
                    <div class="news-v3-in">

                        <h2 class="margin-bottom-5" >
                            <!-- <strong>Call for Full Papers for SIGIR 2020, Xi’an, China</strong> -->
                        </h2>


                        <h3 class="margin-bottom-5" >
                            <strong>The Next Generation of Neural Networks</strong>
                        </h3>
                        <h4>8:30-9:30 - July 27, 2020  <span class="text-danger">(GMT+8)</span></h4>

                        <div class="row abstract">
                            <div class="col-md-12">
                                <p>
                                    Abstract: The most important unsolved problem with artificial neural networks is how
                                    to do unsupervised learning as effectively as the brain. There are currently two
                                    main
                                    approaches to unsupervised learning. In the first approach, exemplified by BERT and
                                    Variational Autoencoders, a deep neural network is used to reconstruct its input.
                                    This is problematic for images
                                    because the deepest layers of the network need to encode the fine details of the
                                    image. An alternative approach, introduced by
                                    Becker and Hinton in 1992, is to train two copies of a deep neural network to
                                    produce output vectors that have
                                    high mutual information when given two different crops of the same image as their
                                    inputs. This approach was designed to allow the representations to be untethered
                                    from irrelevant details
                                    of the input.
                                </p>
                                <p>
                                    The method of optimizing mutual information used by Becker and Hinton was flawed
                                    (for a subtle reason that I will explain) so
                                    Pacannaro and Hinton replaced it by a discriminative objective in which one vector
                                    representation must select a corresponding
                                    vector representation from among many alternatives. With faster hardware,
                                    contrastive learning of representations has recently become very popular
                                    and is proving to be very effective, but it suffers from a major flaw: To learn
                                    pairs of representation vectors that
                                    have N bits of mutual information we need to contrast the correct corresponding
                                    vector with about 2 N incorrect alternatives. I will
                                    describe a novel and effective way of dealing with this limitation. I will also show
                                    that this leads to a simple way of implementing
                                    perceptual learning in cortex.
                                </p>
                            </div>
                        </div>

                        <div class="row abstract">
                            <div class="col-md-4">
                                <div id="organizers">
                                    <ul style="border: 0; ">
                                        <li class="person-card" style="width: 100%; height: auto; ">
                                            <div>
                                                <a target="_blank" href="https://www.cs.toronto.edu/~hinton/">
                                                    <img
                                                        src="{{ site.baseurl }}/assets/img/keynotes/geoffrey-hinton.jpg">Geoffrey
                                                    Hinton</a>
                                                Google Research & Vector Institute, Toronto
                                            </div>
                                        </li>
                                    </ul>
                                </div>
                            </div>
                            <div class="col-md-8">
                                <blockquote class="hero margin-bottom-50">
                                    <p style="line-height: 1.4em !important; font-size: small;">
                                        Geoffrey Hinton received his PhD in Artificial Intelligence from Edinburgh in
                                        1978. After five years as a faculty member at Carnegie-Mellon he became a fellow
                                        of the Canadian Institute for Advanced
                                        Research and moved to the Department of Computer Science at the University of
                                        Toronto where he is now an Emeritus Distinguished Professor. He is also a Vice
                                        President & Engineering Fellow at Google and Chief Scientific Adviser of the
                                        Vector Institute.
                                    </p>
                                    <p style="line-height: 1.4em !important; font-size: small;">
                                        He was one of the researchers who introduced the backpropagation algorithm and
                                        the first to use backpropagation for learning
                                        word embeddings. His other contributions to neural network research include
                                        Boltzmann machines, distributed representations,
                                        time-delay neural nets, mixtures of experts, variational learning and deep
                                        learning. His research group in Toronto made major breakthroughs in deep
                                        learning that revolutionized speech recognition and object classification.
                                    </p>
                                </blockquote>

                            </div>
                        </div>

                        <hr>

                        <!-- On Presuppositions of Machine Learning: A Meta Theory -->
                        <h3 class="margin-bottom-5" >
                            <strong>On Presuppositions of Machine Learning: A Meta Theory</strong>
                        </h3>
                        <h4>14:30-15:30 - July 27, 2020  <span class="text-danger">(GMT+8)</span></h4>

                        <div class="row abstract">
                            <div class="col-md-12">
                                <p>
                                    Abstract: Machine learning (ML) has been run and applied by premising a
                                    series of presuppositions, which contributes both the great success
                                    of AI and the bottleneck of further development of ML. These presuppositions include
                                    (i) the independence assumption of loss function on dataset (Hypothesis I); (ii) the
                                    large capacity assumption on
                                    hypothesis space including solution (Hypothesis II); (iii) the completeness
                                    assumption of training data with high quality (Hypothesis III); and (iv) the
                                    Euclidean assumption on analysis framework
                                    and methodology (Hypothesis IV).
                                </p>
                                <p>
                                    We report, in this presentation, the effort and advances made
                                    by my group on how to break through these presuppositions of
                                    ML and drive ML development. For Hypothesis I, we introduce the
                                    noise modeling principle to adaptively design the loss function of
                                    ML, according to the distribution of data samples, which provides
                                    then a general way to robustlize any ML implementation. For Hypothesis II, we
                                    propose the model driven deep learning approach to define the smallest hypothesis
                                    space of deep neural networks (DNN), which yields not only the very efficient deep
                                    learning, but also a novel way
                                    of DNN design, interpretation and connection with the traditional optimization based
                                    approach. For Hypothesis III, we develop the
                                    axiomatic curriculum learning framework to
                                    learn the patterns from an incomplete dataset step by step and from easy to
                                    difficult, which then provides feasible ways to tackle very
                                    complex incomplete data sets. Finally, For Hypothesis IV, we introduce Banach space
                                    geometry in general, and XU-Roach theorem in
                                    particular, as a possibly useful tool to conduct non-Euclidean analysis of ML
                                    problems. In each case, we present the idea, principles, application examples and
                                    literatures.
                                </p>
                            </div>
                        </div>

                        <div class="row abstract">
                            <div class="col-md-4">
                                <div id="organizers">
                                    <ul style="border: 0; ">
                                        <li class="person-card" style="width: 100%; height: auto;">
                                            <div>
                                                <a target="_blank" href="http://en.xjtu.edu.cn/info/1017/1632.htm">
                                                    <img
                                                        src="{{ site.baseurl }}/assets/img/keynotes/zongben-xu.png">Zongben
                                                    Xu</a>
                                                Xi’an Jiaotong University & Pazhou Lab, Guangzhou
                                            </div>
                                        </li>
                                    </ul>
                                </div>
                            </div>

                            <div class="col-md-8">
                                <blockquote class="hero margin-bottom-50">

                                    <p style="line-height: 1.4em !important; font-size: small;">
                                        Zong-Ben Xu, received his PhD degree in Mathematics in 1987 from Xi’an Jiaotong
                                        University, China. In 1998, he was a postdoctoral Research Fellow in the
                                        Department of Mathematics, The University of
                                        Strathclyde.
                                    </p>
                                    <p style="line-height: 1.4em !important; font-size: small;">
                                        He worked as a Research Fellow in the Department of
                                        Computer Science and Engineering from 1992 to 1994,
                                        and 1996 to 1997, at The Chinese University of Hong
                                        Kong; a visiting professor in the University of Essex in 2001, and Napoli
                                        University in 2002. He has been with
                                        the School of Mathematics and Statistics, Xi’an Jiaotong
                                        University since 1982, where he served as a professor of
                                        mathematics and computer science, Dean of Sciences
                                        (1997-2003), VP of the university (2003-2014) and Chief Scientist of National
                                        Basic Research
                                        Program of China (973 Project). He is currently the director of
                                        Pazhou Lab, Guangzhou and the National Lab for Big Data Analytics, Xi’an. He is
                                        also the Dean of Xi’an Academy of Mathematics
                                        and Mathematical Technology.
                                    </p>
                                    <p style="line-height: 1.4em !important; font-size: small;">
                                        Professor Xu makes several important services for government
                                        and professional societies currently, including Consultant member
                                        of National Big Data Development Commission, the New Generation AI Development
                                        Commission and the National Natural Science Foundation of China. He is VP of
                                        Industrial and Applied Mathematics Society
                                        of China (CSIAM), the director of Big Data and AI
                                        Committee of CSIAM. He is also the co-Editor-in-chief of Journal
                                        of Big Data Analytics and Textbooks Series on Data Science and
                                        Big Data Technology (Higher Education Press of China).
                                    </p>
                                    <p style="line-height: 1.4em !important; font-size: small;">
                                        Professor Xu has published over 280 academic papers on nonlinear functional
                                        analysis, optimization, machine learning and big
                                        data research, most of which are in international journals. His current research
                                        interests include mathematical theory and fundamental algorithms for big data
                                        Analysis, machine learning and data
                                        Science. Professor Xu has gotten many academic awards, say, the
                                        National Natural Science Award (2007), the National Scientific and
                                        Technological Advance Award (2011) of China, CSIAM Su Buchin
                                        Applied Mathematics Award (2008) and Tan Kah Kee Science Award
                                        ( in Information Technology Science, 2018) . He delivered a 45
                                        minute talk at the International Congress of Mathematicians (ICM
                                        2010) upon the invitation of the congress committee. He was elected
                                        as a member of Chinese Academy of Science in 2011.
                                    </p>

                                </blockquote>
                            </div>

                        </div>

                        <hr>


                        <!-- Coopetition in IR Research -->
                        <h3 class="margin-bottom-5" >
                            <strong>Coopetition in IR Research</strong>
                        </h3>
                        <h4>8:30-9:30 - July 28, 2020  <span class="text-danger">(GMT+8)</span></h4>

                        <div class="row abstract">
                            <div class="col-md-12">
                                <p>
                                    Abstract: Coopetitions are activities in which competitors cooperate for a common good.
                                    Community evaluations such as the Text REtrieval
                                    Conference (TREC) are prototypical examples of coopetitions in information retrieval
                                    (IR) and have now been part of the field for
                                    almost thirty years. This longevity and the proliferation of shared evaluation tasks
                                    suggest that, indeed, the net impact of community
                                    evaluations is positive. But what are these benefits, and what are the attendant
                                    costs?
                                </p>

                                <p>
                                    This talk will use TREC tracks as case studies to explore the benefits and
                                    disadvantages of different evaluation task designs. Coopetitions can improve
                                    state-of-the-art effectiveness for a retrieval task by establishing a research
                                    cohort and constructing the
                                    infrastructure–including problem definition, test collections, scoring metrics, and
                                    research methodology–necessary to make progress
                                    on the task. They can also facilitate technology transfer and amortize the
                                    infrastructure costs. The primary danger of coopetitions
                                    is for an entire research community to overfit to some peculiarity of the evaluation
                                    task. This risk can be minimized by building
                                    multiple test sets and regularly updating the evaluation task.
                                </p>

                            </div>


                        </div>

                        <div class="row abstract">
                            <div class="col-md-4">
                                <div id="organizers">
                                    <ul style="border: 0; ">
                                        <li class="person-card" style="width: 100%; height: auto; ">
                                            <div>
                                                <a target="_blank" href="https://www.nist.gov/people/ellen-m-voorhees">
                                                    <img src="{{ site.baseurl }}/assets/img/keynotes/voorhees.jpg">Ellen
                                                    M. Voorhees</a>
                                                National Institute for Standards and Technology
                                            </div>
                                        </li>
                                    </ul>
                                </div>
                            </div>
                            <div class="col-md-8">
                                <blockquote class="hero margin-bottom-50">

                                    <p style="line-height: 1.4em !important; font-size: small;">
                                        Ellen Voorhees is a Senior Research Scientist at the US National
                                        Institute of Standards and Technology (NIST). Her primary responsibility at NIST
                                        is to manage the Text REtrieval Conference (TREC)
                                        project, a project that develops the infrastructure required for large-scale
                                        evaluation of search engines and other information access technology. Voorhees'
                                        research focuses on developing and
                                        validating appropriate evaluation schemes to measure system effectiveness for
                                        diverse user tasks.
                                    </p>
                                    <p style="line-height: 1.4em !important; font-size: small;">
                                        Voorhees received a B.Sc. in computer science from the Pennsylvania State
                                        University, and M.Sc. and Ph.D. degrees in computer
                                        science from Cornell University. Prior to joining NIST she was a Senior Member
                                        of Technical Staff at Siemens Corporate Research
                                        in Princeton, NJ where her work on intelligent agents applied to information
                                        access resulted in three patents. Voorhees is a fellow
                                        of the ACM, a member of AAAI, and has been elected as a fellow of the Washington
                                        Academy of Sciences. She has published
                                        numerous articles on information retrieval techniques and evaluation
                                        methodologies and serves on the review boards of journals and
                                        conferences.
                                    </p>
                                </blockquote>
                            </div>
                        </div>

                        <hr>

                        <!-- Proof by Experimentation? Towards Better IR Research -->
                        <h3 class="margin-bottom-5" >
                            <strong>Proof by Experimentation? Towards Better IR Research</strong>
                        </h3>
                        <h4>14:30-15:30 - July 28, 2020  <span class="text-danger">(GMT+8)</span></h4>

                        <div class="row abstract">
                            <div class="col-md-12">
                                <p>
                                    Abstract: The current fight against the COVID-19 pandemic illustrates the
                                    importance of proper scientific methods: Besides fake news lacking
                                    any factual evidence, reports on clinical trials with various drugs
                                    often yield contradicting results; here, only a closer look at the
                                    underlying empirical methodology can help in forming a clearer
                                    picture.
                                </p>
                                <p>
                                    In IR research, empirical foundation in the form of experiments
                                    plays an important role. However, the methods applied often are
                                    not at the level of scientific standards that hold in many other disciplines, as IR
                                    experiments are frequently flawed in several ways:
                                    Measures like MRR or ERR are invalid by definition, and MAP is
                                    based on unrealistic assumptions about user behaviour; computing
                                    relative improvements of arithmetic means is statistical nonsense;
                                    test hypotheses often are formulated after the experiment has been
                                    carried out; multiple hypotheses are tested without correction;
                                    many experiments are not reproducible results or are compared to
                                    weak baselines [<a href="https://dl.acm.org/doi/10.1145/1645953.1646031">1</a>, <a
                                        href="https://dl.acm.org/doi/10.1145/3308774.3308781">6</a>]; frequent reuse of
                                    the same test collections
                                    yields random results [<a
                                        href="https://dl.acm.org/doi/10.1145/2766462.2767812">2</a>]; authors (and
                                    reviewers) believe that experiments prove
                                    the claims made. Methods for overcoming these
                                    problems have been pointed out [<a
                                        href="https://dl.acm.org/doi/10.1145/3190580.3190586">5</a>], but are still
                                    widely ignored.
                                </p>

                                <p>

                                    However, even when experimental results have been achieved
                                    via proper methods, this only solves the issue of internal validity.
                                    The problem of external validity has hardly been addressed in IR
                                    so far. Just having empirical results for a handful or test collections
                                    does not enable us to make any statements on how far we can
                                    generalise these observations. So we should put more emphasis on
                                    understanding why certain methods work (or don’t work) under
                                    certain circumstances - instead of looking at improvements at the
                                    third or fourth decimal place. This would allow us to make more
                                    generally valid statements, and be a first step towards being able to
                                    predict performance for new collections [<a
                                        href="https://dl.acm.org/doi/10.1145/3274784.3274789">3</a>, <a
                                        href="https://dl.acm.org/doi/10.1145/2422256.2422259">4</a>].
                                </p>

                                <p>
                                    To conclude, better research in IR can only be achieved by
                                    <ul>
                                        <li>Enforcing rigorous experimental methodology at our top
                                            venues.</li>
                                        <li>Establishing leaderboards and carrying out metastudies for
                                            monitoring the actual scientific progress in our field.</li>
                                        <li>Understanding should be valued higher than raw performance.</li>
                                        <li>Ultimately, research should aim more at performance prediction than at
                                            performance
                                            measurement.</li>
                                    </ul>
                                </p>

                            </div>
                            <div class="row abstract">
                                <div class="col-md-4">
                                    <div id="organizers">
                                        <ul style="border: 0; ">
                                            <li class="person-card" style="width: 100%; height: auto; ">
                                                <div>
                                                    <a target="_blank"
                                                        href="http://www.is.informatik.uni-duisburg.de/staff/fuhr.html">
                                                        <img
                                                            src="{{ site.baseurl }}/assets/img/keynotes/Norbert_Fuhr.jpg">Norbert
                                                        Fuhr</a>
                                                    University of Duisburg-Essen, Germany
                                                </div>
                                            </li>
                                        </ul>



                                    </div>
                                </div>
                                <div class="col-md-8">
                                    <blockquote class="hero margin-bottom-50">
                                        <p style="line-height: 1.4em !important; font-size: small;">
                                            Norbert Fuhr holds a PhD (Dr.) in Computer Science from the
                                            Technical University of Darmstadt, which he received in 1986.
                                            He became Associate Professor in the computer science department of the
                                            University of Dortmund in 1991 and was appointed Full Professor for computer
                                            science at the University
                                            of Duisburg-Essen in 2002.
                                        </p>
                                        <p style="line-height: 1.4em !important; font-size: small;">
                                            His past research dealt with topics such as probabilistic retrieval models,
                                            the
                                            integration
                                            of IR and databases, retrieval in distributed digital libraries and XML
                                            documents, and user friendly
                                            retrieval interfaces. His current research interests are models for
                                            interactive retrieval, social media retrieval, and evaluation methodology.
                                        </p>
                                        <p style="line-height: 1.4em !important; font-size: small;">
                                            Norbert Fuhr has served as PC member and program chair of major conferences
                                            in IR and digital libraries, and on the editorial
                                            boards of several journals in these areas. In 2012, he received the Gerald
                                            Salton Award of ACM-SIGIR.
                                        </p>
                                    </blockquote>
                                </div>
                            </div>

                        </div>

                        <hr>

                        <!-- From Information to Assistance -->
                        <h3 class="margin-bottom-5" >
                            <strong>From Information to Assistance</strong>
                        </h3>
                        <h4>8:30-9:30 - July 29, 2020  <span class="text-danger">(GMT+8)</span></h4>

                        <div class="row abstract">
                            <div class="col-md-12">
                                <p>
                                    Abstract: “Knowledge is of two kinds. We know a subject ourselves, or we know where we can
                                    find information upon it. When we enquire into any subject, the first thing we have
                                    to do is to know what books have treated of it. This leads us to look at catalogues,
                                    and at the backs of books in libraries.” – Samuel Johnson (Boswell’s Life of
                                    Johnson)
                                </p>
                                <p>
                                    When Johnson was writing this, said libraries were very exclusive, inaccessible to
                                    most. When I was growing up the library was a favorite place to find information
                                    with the help of expert assistants, trained librarians. Nowadays, while libraries
                                    are still one of my favorite institutions, we have powerful digital information
                                    search, retrieval, and assemblage services, bundled into easily accessible tools at
                                    our fingertips.
                                </p>
                                <p>
                                    As information proliferates and human information needs remain high, information
                                    retrieval will continue to be a central area of investigation. We will also need
                                    better and better tools to access, assemble, and represent that information in ways
                                    that can be understood and applied-tools that ensure information turns into
                                    knowledge that is useful and used.
                                </p>

                                <p>
                                    In this talk, I will focus on how people find information, and how the tools we
                                    build aid in that finding. Using case studies, I will outline some that remain
                                    challenging, and offer some case studies and edge cases where more work is needed. I
                                    will share thoughts on how emerging assistant devices and services are and are not
                                    meeting the challenge of becoming expert information assistants.
                                </p>

                            </div>


                        </div>
                        <div class="row abstract">
                            <div class="col-md-4">
                                <div id="organizers">
                                    <ul style="border: 0; ">
                                        <li class="person-card" style="width: 100%; height: auto; ">
                                            <div>
                                                <a target="_blank" href="http://elizabethchurchill.com/about/">
                                                    <img
                                                        src="{{ site.baseurl }}/assets/img/keynotes/Churchill.png">Elizabeth
                                                    F. Churchill</a>
                                                Google, USA
                                            </div>
                                        </li>
                                    </ul>
                                </div>
                            </div>
                            <div class="col-md-8">
                                <blockquote class="hero margin-bottom-50">
                                    <p style="line-height: 1.4em !important; font-size: small;">
                                        Elizabeth Churchill is a Director of UX at Google. She is also the Executive
                                        Vice President of the Association of Computing Machinery (ACM), a member of the
                                        ACM’s CHI Academy, and an ACM Fellow, Distinguished Scientist, and Distinguished
                                        Speaker. With a background in psychology, Artificial Intelligence and Cognitive
                                        Science, she draws on social, computer, engineering and data sciences to create
                                        innovative digital tools, applications, and services. She has built research
                                        teams at Google, eBay, Yahoo, PARC and FujiXerox. She holds a PhD from the
                                        University of Cambridge and honorary doctorates from the University of Sussex,
                                        and the University of Stockholm. In 2016, she received the Citris-Banatao
                                        Institute Athena Award for Executive Leadership.
                                    </p>
                                </blockquote>
                            </div>
                        </div>

                        <hr>

                        <!-- How Deep Learning Works for Information Retrieval -->
                        <h3 class="margin-bottom-5" >
                            <strong>How Deep Learning Works for Information Retrieval</strong>
                        </h3>
                        <h4>14:30-15:30 - July 29, 2020 <span class="text-danger">(GMT+8)</span></h4>

                        <div class="row abstract">
                            <div class="col-md-12">
                                <p>
                                    Information retrieval (IR) is the science of search, the search of
                                    user query relevant pieces of information from a collection of
                                    unstructured resources. Information in this context includes text,
                                    imagery, audio, video, xml, program, and metadata. The journey
                                    of an IR process begins with a user query sent to the IR system
                                    which encodes the query, compares the query with the available
                                    resources, and returns the most relevant pieces of information.
                                    Thus, the system is equipped with the ability to store, retrieve and
                                    maintain information.
                                </p>

                                <p>
                                    In the early era of IR, the whole process was completed using
                                    handcrafted features and ad-hoc relevance measures. Later,
                                    principled frameworks for relevance measure were developed with
                                    statistical learning as a basis. Recently, deep learning has proven
                                    essential to the introduction of more opportunities to IR. This is
                                    because data-driven features combined with data-driven relevance
                                    measures can effectively eliminate the human bias in either feature
                                    or relevance measure design.
                                </p>
                                <p>
                                    Deep learning has shown its significant potential to transform IR
                                    evidenced by abundant empirical results. However, we continue to
                                    strive to gain a comprehensive understanding of deep learning.
                                    This is done by answering questions such as why deep structures
                                    are superior to shallow structures, how skip connections affect a
                                    model’s performance, uncovering the potential relationship
                                    between some of the hyper-parameters and a model’s
                                    performance, and exploring ways to reduce the chance for deep
                                    models to be fooled by adversaries. Answering such questions can
                                    help design more effective deep models and devise more efficient
                                    schemes for model training.
                                </p>

                            </div>

                        </div>

                        <div class="row abstract">
                            <div class="col-md-4">
                                <div id="organizers">
                                    <ul style="border: 0; ">
                                        <li class="person-card" style="width: 100%; height: auto; ">
                                            <div>
                                                <a target="_blank"
                                                    href="https://www.sydney.edu.au/engineering/about/our-people/academic-staff/dacheng-tao.html">
                                                    <img
                                                        src="{{ site.baseurl }}/assets/img/keynotes/dacheng.png">Dacheng
                                                    Tao</a>
                                                The University of Sydney, Australia
                                            </div>
                                        </li>
                                    </ul>
                                </div>
                            </div>

                            <div class="col-md-8">
                                <blockquote class="hero margin-bottom-50">
                                    <p style="line-height: 1.4em !important; font-size: small;">
                                        Dacheng Tao is Professor of Computer Science and ARC Laureate
                                        Fellow in the School of Computer Science and the Faculty of
                                        Engineering, and the Inaugural Director of the UBTECH Sydney
                                        Artificial Intelligence Centre, at The University of Sydney. His
                                        research results in artificial intelligence have expounded in one
                                        monograph and 200+ publications at learning journals and
                                        conferences, such as IEEE TPAMI, AAAI, IJCAI, NeurIPS,
                                        ICML, CVPR, ICCV, ECCV, ICDM, and KDD, with several best
                                        paper awards. He received the 2018 IEEE ICDM Research
                                        Contributions Award and the 2015 Australian Museum Scopus-Eureka prize. He
                                        is a
                                        Fellow of the IEEE, the ACM and the
                                        Australian Academy of Science.
                                    </p>
                                </blockquote>
                            </div>

                        </div>




                    </div>
                </div>
            </div>
            <!--/end container-->
        </div>
        <!--=== End Content ===-->


        <!--=== Footer ===-->
        {% include footer.html %}
        <!--=== End Footer ===-->

        <!--=== Scripts ===-->
        {% include scripts.html %}
        <!--=== End scripts ===-->

</body>

</html>
